{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntar QueroTruck e Grupo Vamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o arquivo Excel\n",
    "arquivo_excel = 'dados_queroTruck_grupoVamos.xlsx'\n",
    "\n",
    "# Verificar as abas disponíveis no arquivo\n",
    "excel_file = pd.ExcelFile(arquivo_excel)\n",
    "print(\"Abas disponíveis no arquivo:\", excel_file.sheet_names)\n",
    "\n",
    "# Carregar os dados (ajustar com base nas abas disponíveis)\n",
    "if 'QueroTruck' in excel_file.sheet_names and 'GrupoVamos' in excel_file.sheet_names:\n",
    "    aba1 = pd.read_excel(arquivo_excel, sheet_name='QueroTruck')\n",
    "    aba2 = pd.read_excel(arquivo_excel, sheet_name='GrupoVamos')\n",
    "    dados_combinados = pd.concat([aba1, aba2], ignore_index=True)\n",
    "else:\n",
    "    print(\"Abas 'QueroTruck' e/ou 'GrupoVamos' não encontradas. Carregando a primeira aba disponível.\")\n",
    "    dados_combinados = pd.read_excel(arquivo_excel, sheet_name=excel_file.sheet_names[0])\n",
    "\n",
    "# Selecionar apenas as colunas esperadas\n",
    "colunas_esperadas = ['Marca', 'Modelo', 'Preço', 'Quilometragem', 'Ano', 'Localização']\n",
    "dados_combinados = dados_combinados[colunas_esperadas]\n",
    "\n",
    "# Função para limpar a coluna 'Localização'\n",
    "def limpar_localizacao(row):\n",
    "    # Pegar o valor da coluna 'Localização' e converter para string\n",
    "    localizacao = str(row['Localização'])\n",
    "    \n",
    "    # Se a célula for \"nan\" ou \"Tirar\", retornar como está\n",
    "    if localizacao == 'nan' or localizacao == 'Tirar':\n",
    "        return localizacao\n",
    "    \n",
    "    # Normalizar quebras de linha (substituir \\r\\n por \\n)\n",
    "    localizacao = localizacao.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "    \n",
    "    # Dividir o texto em linhas\n",
    "    linhas = localizacao.split('\\n')\n",
    "    \n",
    "    # Remover espaços em branco e converter para maiúsculas para verificação\n",
    "    linhas_upper = [linha.strip().upper() for linha in linhas]\n",
    "    \n",
    "    # Depuração: Mostrar o texto original e as linhas processadas\n",
    "    print(f\"Texto original: {localizacao}\")\n",
    "    print(f\"Linhas (upper): {linhas_upper}\")\n",
    "    \n",
    "    # Verificar se \"Anunciante\" está presente\n",
    "    if any(linha_upper == 'ANUNCIANTE' for linha_upper in linhas_upper):\n",
    "        print(\"Detectado 'Anunciante'\")\n",
    "        novas_linhas = []\n",
    "        i = 0\n",
    "        while i < len(linhas):\n",
    "            if linhas_upper[i] == 'ANUNCIANTE':\n",
    "                # Pular \"Anunciante\" e a próxima linha (nome do anunciante), se existir\n",
    "                print(f\"Removendo 'Anunciante' na posição {i}\")\n",
    "                i += 2\n",
    "            else:\n",
    "                # Manter a linha se não for \"Anunciante\"\n",
    "                if linhas[i].strip():  # Ignorar linhas vazias\n",
    "                    novas_linhas.append(linhas[i])\n",
    "                i += 1\n",
    "        print(f\"Após remover 'Anunciante' e nome: {novas_linhas}\")\n",
    "        return '\\n'.join(novas_linhas).strip() if novas_linhas else ''\n",
    "    \n",
    "    # Verificar se \"ABAIXO FIPE\" está presente\n",
    "    if any(linha_upper == 'ABAIXO FIPE' for linha_upper in linhas_upper):\n",
    "        print(\"Detectado 'ABAIXO FIPE'\")\n",
    "        novas_linhas = [linha for linha, linha_upper in zip(linhas, linhas_upper) if linha_upper != 'ABAIXO FIPE' and linha.strip() != '']\n",
    "        print(f\"Após remover 'ABAIXO FIPE': {novas_linhas}\")\n",
    "        return '\\n'.join(novas_linhas).strip() if novas_linhas else localizacao\n",
    "    \n",
    "    # Se não contém \"Anunciante\" nem \"ABAIXO FIPE\", retornar o texto original\n",
    "    print(\"Nenhum 'Anunciante' ou 'ABAIXO FIPE' detectado\")\n",
    "    return localizacao\n",
    "\n",
    "# Aplicar a função para limpar a coluna 'Localização'\n",
    "dados_combinados['Localização'] = dados_combinados.apply(limpar_localizacao, axis=1)\n",
    "\n",
    "# Salvar o arquivo final\n",
    "dados_combinados.to_excel('dados_Truck&Vamos.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juntar com Truncadão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "arquivo_excel1 = 'dados_Truck&Vamos.xlsx'  \n",
    "arquivo_excel2 = 'dados_trucadao_completos.xlsx'  \n",
    "\n",
    "dados1 = pd.read_excel(arquivo_excel1)  \n",
    "dados2 = pd.read_excel(arquivo_excel2)  \n",
    "\n",
    "dados_combinados = pd.concat([dados1, dados2], ignore_index=True)\n",
    "\n",
    "colunas_esperadas = ['Marca', 'Modelo', 'Preço', 'Quilometragem', 'Ano', 'Localização']\n",
    "dados_combinados = dados_combinados[colunas_esperadas]\n",
    "\n",
    "dados_combinados.to_excel('Caminhoes_Cavalos.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
